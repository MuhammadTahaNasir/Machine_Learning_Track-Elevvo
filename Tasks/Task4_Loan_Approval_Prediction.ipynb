{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Loan Approval Prediction\n",
    "\n",
    "## Objective\n",
    "Build a model to predict whether a loan application will be approved\n",
    "\n",
    "## Dataset\n",
    "Loan Approval Prediction Dataset (Simulated for demonstration)\n",
    "\n",
    "## Tasks:\n",
    "1. Handle missing values and encode categorical features\n",
    "2. Train a classification model and evaluate performance on imbalanced data\n",
    "3. Focus on precision, recall, and F1-score\n",
    "4. Bonus: Use SMOTE or other techniques to address class imbalance\n",
    "5. Bonus: Try logistic regression vs. decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\levi uchiha\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\levi uchiha\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\levi uchiha\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (1.7.0)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Using cached sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\levi uchiha\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\levi uchiha\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Collecting scikit-learn<2,>=1.3.2 (from imbalanced-learn)\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Using cached imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Using cached sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 297.8 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.5/11.1 MB 297.8 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.5/11.1 MB 297.8 kB/s eta 0:00:36\n",
      "   - -------------------------------------- 0.5/11.1 MB 297.8 kB/s eta 0:00:36\n",
      "   -- ------------------------------------- 0.8/11.1 MB 296.2 kB/s eta 0:00:35\n",
      "   -- ------------------------------------- 0.8/11.1 MB 296.2 kB/s eta 0:00:35\n",
      "   -- ------------------------------------- 0.8/11.1 MB 296.2 kB/s eta 0:00:35\n",
      "   -- ------------------------------------- 0.8/11.1 MB 296.2 kB/s eta 0:00:35\n",
      "   -- ------------------------------------- 0.8/11.1 MB 296.2 kB/s eta 0:00:35\n",
      "   --- ------------------------------------ 1.0/11.1 MB 297.2 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.0/11.1 MB 297.2 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.0/11.1 MB 297.2 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.0/11.1 MB 297.2 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 298.7 kB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 298.7 kB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 298.7 kB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 298.7 kB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 304.2 kB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 304.2 kB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 304.2 kB/s eta 0:00:32\n",
      "   ------ --------------------------------- 1.8/11.1 MB 310.4 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 1.8/11.1 MB 310.4 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 1.8/11.1 MB 310.4 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 1.8/11.1 MB 310.4 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 2.1/11.1 MB 311.1 kB/s eta 0:00:29\n",
      "   ------- -------------------------------- 2.1/11.1 MB 311.1 kB/s eta 0:00:29\n",
      "   ------- -------------------------------- 2.1/11.1 MB 311.1 kB/s eta 0:00:29\n",
      "   ------- -------------------------------- 2.1/11.1 MB 311.1 kB/s eta 0:00:29\n",
      "   ------- -------------------------------- 2.1/11.1 MB 311.1 kB/s eta 0:00:29\n",
      "   -------- ------------------------------- 2.4/11.1 MB 308.9 kB/s eta 0:00:29\n",
      "   -------- ------------------------------- 2.4/11.1 MB 308.9 kB/s eta 0:00:29\n",
      "   -------- ------------------------------- 2.4/11.1 MB 308.9 kB/s eta 0:00:29\n",
      "   --------- ------------------------------ 2.6/11.1 MB 311.4 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 2.6/11.1 MB 311.4 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 2.6/11.1 MB 311.4 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 2.6/11.1 MB 311.4 kB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 315.5 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 315.5 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 315.5 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 315.5 kB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 318.3 kB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 318.3 kB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 318.3 kB/s eta 0:00:25\n",
      "   ------------ --------------------------- 3.4/11.1 MB 319.4 kB/s eta 0:00:24\n",
      "   ------------ --------------------------- 3.4/11.1 MB 319.4 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 3.7/11.1 MB 330.9 kB/s eta 0:00:23\n",
      "   ------------- -------------------------- 3.7/11.1 MB 330.9 kB/s eta 0:00:23\n",
      "   ------------- -------------------------- 3.7/11.1 MB 330.9 kB/s eta 0:00:23\n",
      "   -------------- ------------------------- 3.9/11.1 MB 336.2 kB/s eta 0:00:22\n",
      "   -------------- ------------------------- 3.9/11.1 MB 336.2 kB/s eta 0:00:22\n",
      "   -------------- ------------------------- 3.9/11.1 MB 336.2 kB/s eta 0:00:22\n",
      "   -------------- ------------------------- 3.9/11.1 MB 336.2 kB/s eta 0:00:22\n",
      "   --------------- ------------------------ 4.2/11.1 MB 337.9 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.1 MB 337.9 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.1 MB 337.9 kB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 340.0 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 340.0 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 340.0 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 340.0 kB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 338.7 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 338.7 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 338.7 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 338.7 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 335.2 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 335.2 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 335.2 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 335.2 kB/s eta 0:00:19\n",
      "   ------------------ --------------------- 5.2/11.1 MB 335.3 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.2/11.1 MB 335.3 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.2/11.1 MB 335.3 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.2/11.1 MB 335.3 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 5.5/11.1 MB 336.9 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.5/11.1 MB 336.9 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.5/11.1 MB 336.9 kB/s eta 0:00:17\n",
      "   -------------------- ------------------- 5.8/11.1 MB 337.9 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.8/11.1 MB 337.9 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.8/11.1 MB 337.9 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.8/11.1 MB 337.9 kB/s eta 0:00:16\n",
      "   --------------------- ------------------ 6.0/11.1 MB 339.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.1 MB 339.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.1 MB 339.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.1 MB 339.3 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 337.5 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 337.5 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 337.5 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 340.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 340.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 340.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 340.5 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.1 MB 337.5 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.8/11.1 MB 337.5 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.8/11.1 MB 337.5 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.8/11.1 MB 337.5 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.8/11.1 MB 337.5 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.1/11.1 MB 333.0 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 7.1/11.1 MB 333.0 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 7.1/11.1 MB 333.0 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 7.1/11.1 MB 333.0 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 7.1/11.1 MB 333.0 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.1 MB 330.1 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.1 MB 330.1 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.1 MB 330.1 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.1 MB 330.1 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 7.6/11.1 MB 328.7 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.1 MB 328.7 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.1 MB 328.7 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.1 MB 328.7 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 328.5 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 328.5 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 328.5 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 328.5 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 328.5 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 328.5 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 328.5 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 328.5 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 8.4/11.1 MB 328.2 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 8.4/11.1 MB 328.2 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 8.4/11.1 MB 328.2 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 8.4/11.1 MB 328.2 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 8.4/11.1 MB 328.2 kB/s eta 0:00:09\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.7/11.1 MB 325.1 kB/s eta 0:00:08\n",
      "   -------------------------------- ------- 8.9/11.1 MB 313.6 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.9/11.1 MB 313.6 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.9/11.1 MB 313.6 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.9/11.1 MB 313.6 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.9/11.1 MB 313.6 kB/s eta 0:00:07\n",
      "   --------------------------------- ------ 9.2/11.1 MB 311.0 kB/s eta 0:00:07\n",
      "   --------------------------------- ------ 9.2/11.1 MB 311.0 kB/s eta 0:00:07\n",
      "   --------------------------------- ------ 9.2/11.1 MB 311.0 kB/s eta 0:00:07\n",
      "   --------------------------------- ------ 9.2/11.1 MB 311.0 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 310.3 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 310.3 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 310.3 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 310.3 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 310.3 kB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 309.5 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 309.5 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 309.5 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 309.5 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 309.1 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 309.1 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 309.1 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 309.1 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 309.1 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 10.2/11.1 MB 307.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.2/11.1 MB 307.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.2/11.1 MB 307.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.2/11.1 MB 307.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.2/11.1 MB 307.7 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.5/11.1 MB 304.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.1 MB 304.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.1 MB 304.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.1 MB 304.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.1 MB 304.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.1 MB 304.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.7/11.1 MB 300.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.7/11.1 MB 300.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.7/11.1 MB 300.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.7/11.1 MB 300.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.7/11.1 MB 300.1 kB/s eta 0:00:02\n",
      "   ---------------------------------------  11.0/11.1 MB 297.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 297.9 kB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn, sklearn-compat, imbalanced-learn\n",
      "\n",
      "  Attempting uninstall: scikit-learn\n",
      "\n",
      "    Found existing installation: scikit-learn 1.7.0\n",
      "\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "    Uninstalling scikit-learn-1.7.0:\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "      Successfully uninstalled scikit-learn-1.7.0\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ---------------------------------------- 0/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [sklearn-compat]\n",
      "   ------------- -------------------------- 1/3 [sklearn-compat]\n",
      "   ------------- -------------------------- 1/3 [sklearn-compat]\n",
      "   ------------- -------------------------- 1/3 [sklearn-compat]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   -------------------------- ------------- 2/3 [imbalanced-learn]\n",
      "   ---------------------------------------- 3/3 [imbalanced-learn]\n",
      "\n",
      "Successfully installed imbalanced-learn-0.13.0 scikit-learn-1.6.1 sklearn-compat-0.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Levi Uchiha\\AppData\\Roaming\\Python\\Python313\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn==1.3.2\n",
      "  Downloading scikit-learn-1.3.2.tar.gz (7.5 MB)\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.5 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     -- ------------------------------------- 0.5/7.5 MB 97.2 kB/s eta 0:01:12\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 100.3 kB/s eta 0:01:08\n",
      "     ----- ---------------------------------- 1.0/7.5 MB 112.2 kB/s eta 0:00:58\n",
      "     ----- ---------------------------------- 1.0/7.5 MB 112.2 kB/s eta 0:00:58\n",
      "     ----- ---------------------------------- 1.0/7.5 MB 112.2 kB/s eta 0:00:58\n",
      "     ----- ---------------------------------- 1.0/7.5 MB 112.2 kB/s eta 0:00:58\n",
      "     ----- ---------------------------------- 1.0/7.5 MB 112.2 kB/s eta 0:00:58\n",
      "     ----- ---------------------------------- 1.0/7.5 MB 112.2 kB/s eta 0:00:58\n",
      "     ----- ---------------------------------- 1.0/7.5 MB 112.2 kB/s eta 0:00:58\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     ------ --------------------------------- 1.3/7.5 MB 125.1 kB/s eta 0:00:50\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     -------- ------------------------------- 1.6/7.5 MB 126.7 kB/s eta 0:00:47\n",
      "     --------- ------------------------------ 1.8/7.5 MB 128.3 kB/s eta 0:00:45\n",
      "     --------- ------------------------------ 1.8/7.5 MB 128.3 kB/s eta 0:00:45\n",
      "     --------- ------------------------------ 1.8/7.5 MB 128.3 kB/s eta 0:00:45\n",
      "     --------- ------------------------------ 1.8/7.5 MB 128.3 kB/s eta 0:00:45\n",
      "     --------- ------------------------------ 1.8/7.5 MB 128.3 kB/s eta 0:00:45\n",
      "     --------- ------------------------------ 1.8/7.5 MB 128.3 kB/s eta 0:00:45\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 134.8 kB/s eta 0:00:41\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 134.8 kB/s eta 0:00:41\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 134.8 kB/s eta 0:00:41\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 134.8 kB/s eta 0:00:41\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 134.8 kB/s eta 0:00:41\n",
      "     ------------ --------------------------- 2.4/7.5 MB 142.6 kB/s eta 0:00:37\n",
      "     ------------ --------------------------- 2.4/7.5 MB 142.6 kB/s eta 0:00:37\n",
      "     ------------ --------------------------- 2.4/7.5 MB 142.6 kB/s eta 0:00:37\n",
      "     ------------ --------------------------- 2.4/7.5 MB 142.6 kB/s eta 0:00:37\n",
      "     ------------ --------------------------- 2.4/7.5 MB 142.6 kB/s eta 0:00:37\n",
      "     ------------ --------------------------- 2.4/7.5 MB 142.6 kB/s eta 0:00:37\n",
      "     ------------- -------------------------- 2.6/7.5 MB 149.5 kB/s eta 0:00:33\n",
      "     ------------- -------------------------- 2.6/7.5 MB 149.5 kB/s eta 0:00:33\n",
      "     ------------- -------------------------- 2.6/7.5 MB 149.5 kB/s eta 0:00:33\n",
      "     ------------- -------------------------- 2.6/7.5 MB 149.5 kB/s eta 0:00:33\n",
      "     ------------- -------------------------- 2.6/7.5 MB 149.5 kB/s eta 0:00:33\n",
      "     ------------- -------------------------- 2.6/7.5 MB 149.5 kB/s eta 0:00:33\n",
      "     ------------- -------------------------- 2.6/7.5 MB 149.5 kB/s eta 0:00:33\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     --------------- ------------------------ 2.9/7.5 MB 151.1 kB/s eta 0:00:31\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 149.8 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------ --------------------- 3.4/7.5 MB 139.1 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     ------------------- -------------------- 3.7/7.5 MB 130.7 kB/s eta 0:00:30\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     -------------------- ------------------- 3.9/7.5 MB 124.6 kB/s eta 0:00:29\n",
      "     ---------------------- ----------------- 4.2/7.5 MB 129.9 kB/s eta 0:00:26\n",
      "     ---------------------- ----------------- 4.2/7.5 MB 129.9 kB/s eta 0:00:26\n",
      "     ---------------------- ----------------- 4.2/7.5 MB 129.9 kB/s eta 0:00:26\n",
      "     ---------------------- ----------------- 4.2/7.5 MB 129.9 kB/s eta 0:00:26\n",
      "     ---------------------- ----------------- 4.2/7.5 MB 129.9 kB/s eta 0:00:26\n",
      "     ----------------------- ---------------- 4.5/7.5 MB 133.8 kB/s eta 0:00:23\n",
      "     ----------------------- ---------------- 4.5/7.5 MB 133.8 kB/s eta 0:00:23\n",
      "     ----------------------- ---------------- 4.5/7.5 MB 133.8 kB/s eta 0:00:23\n",
      "     ----------------------- ---------------- 4.5/7.5 MB 133.8 kB/s eta 0:00:23\n",
      "     ----------------------- ---------------- 4.5/7.5 MB 133.8 kB/s eta 0:00:23\n",
      "     ----------------------- ---------------- 4.5/7.5 MB 133.8 kB/s eta 0:00:23\n",
      "     ------------------------- -------------- 4.7/7.5 MB 140.2 kB/s eta 0:00:20\n",
      "     ------------------------- -------------- 4.7/7.5 MB 140.2 kB/s eta 0:00:20\n",
      "     ------------------------- -------------- 4.7/7.5 MB 140.2 kB/s eta 0:00:20\n",
      "     ------------------------- -------------- 4.7/7.5 MB 140.2 kB/s eta 0:00:20\n",
      "     ------------------------- -------------- 4.7/7.5 MB 140.2 kB/s eta 0:00:20\n",
      "     ------------------------- -------------- 4.7/7.5 MB 140.2 kB/s eta 0:00:20\n",
      "     -------------------------- ------------- 5.0/7.5 MB 143.1 kB/s eta 0:00:18\n",
      "     -------------------------- ------------- 5.0/7.5 MB 143.1 kB/s eta 0:00:18\n",
      "     -------------------------- ------------- 5.0/7.5 MB 143.1 kB/s eta 0:00:18\n",
      "     -------------------------- ------------- 5.0/7.5 MB 143.1 kB/s eta 0:00:18\n",
      "     --------------------------- ------------ 5.2/7.5 MB 147.1 kB/s eta 0:00:16\n",
      "     --------------------------- ------------ 5.2/7.5 MB 147.1 kB/s eta 0:00:16\n",
      "     --------------------------- ------------ 5.2/7.5 MB 147.1 kB/s eta 0:00:16\n",
      "     --------------------------- ------------ 5.2/7.5 MB 147.1 kB/s eta 0:00:16\n",
      "     --------------------------- ------------ 5.2/7.5 MB 147.1 kB/s eta 0:00:16\n",
      "     --------------------------- ------------ 5.2/7.5 MB 147.1 kB/s eta 0:00:16\n",
      "     ----------------------------- ---------- 5.5/7.5 MB 150.3 kB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 5.5/7.5 MB 150.3 kB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 5.5/7.5 MB 150.3 kB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 5.5/7.5 MB 150.3 kB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 5.5/7.5 MB 150.3 kB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 5.5/7.5 MB 150.3 kB/s eta 0:00:14\n",
      "     ----------------------------- ---------- 5.5/7.5 MB 150.3 kB/s eta 0:00:14\n",
      "     ------------------------------ --------- 5.8/7.5 MB 149.2 kB/s eta 0:00:12\n",
      "     ------------------------------ --------- 5.8/7.5 MB 149.2 kB/s eta 0:00:12\n",
      "     ------------------------------ --------- 5.8/7.5 MB 149.2 kB/s eta 0:00:12\n",
      "     ------------------------------ --------- 5.8/7.5 MB 149.2 kB/s eta 0:00:12\n",
      "     ------------------------------ --------- 5.8/7.5 MB 149.2 kB/s eta 0:00:12\n",
      "     ------------------------------ --------- 5.8/7.5 MB 149.2 kB/s eta 0:00:12\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     -------------------------------- ------- 6.0/7.5 MB 152.8 kB/s eta 0:00:10\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     --------------------------------- ------ 6.3/7.5 MB 151.2 kB/s eta 0:00:09\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 133.7 kB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 133.7 kB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 133.7 kB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 133.7 kB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 133.7 kB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 133.7 kB/s eta 0:00:08\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 133.7 kB/s eta 0:00:08\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------ --- 6.8/7.5 MB 134.4 kB/s eta 0:00:06\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ------------------------------------- -- 7.1/7.5 MB 135.1 kB/s eta 0:00:04\n",
      "     ---------------------------------------  7.3/7.5 MB 137.0 kB/s eta 0:00:02\n",
      "     ---------------------------------------  7.3/7.5 MB 137.0 kB/s eta 0:00:02\n",
      "     ---------------------------------------  7.3/7.5 MB 137.0 kB/s eta 0:00:02\n",
      "     ---------------------------------------  7.3/7.5 MB 137.0 kB/s eta 0:00:02\n",
      "     ---------------------------------------  7.3/7.5 MB 137.0 kB/s eta 0:00:02\n",
      "     ---------------------------------------  7.3/7.5 MB 137.0 kB/s eta 0:00:02\n",
      "     ---------------------------------------- 7.5/7.5 MB 137.1 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "   Preparing metadata (pyproject.toml) did not run successfully.\n",
      "   exit code: 1\n",
      "  > [649 lines of output]\n",
      "      Partial import of sklearn during the build process.\n",
      "      test_program.c\n",
      "      Generating code\n",
      "      Finished generating code\n",
      "      test_program.c\n",
      "      LINK : warning LNK4044: unrecognized option '/openmp'; ignored\n",
      "      Generating code\n",
      "      Finished generating code\n",
      "      Compiling sklearn\\__check_build\\_check_build.pyx because it changed.\n",
      "      Compiling sklearn\\_isotonic.pyx because it changed.\n",
      "      Compiling sklearn\\_loss\\_loss.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_dbscan_inner.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_hierarchical_fast.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_common.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_lloyd.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_elkan.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_k_means_minibatch.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_hdbscan\\_linkage.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_hdbscan\\_reachability.pyx because it changed.\n",
      "      Compiling sklearn\\cluster\\_hdbscan\\_tree.pyx because it changed.\n",
      "      Compiling sklearn\\datasets\\_svmlight_format_fast.pyx because it changed.\n",
      "      Compiling sklearn\\decomposition\\_online_lda_fast.pyx because it changed.\n",
      "      Compiling sklearn\\decomposition\\_cdnmf_fast.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_gradient_boosting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx because it changed.\n",
      "      Compiling sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx because it changed.\n",
      "      Compiling sklearn\\feature_extraction\\_hashing_fast.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_cd_fast.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_sgd_fast.pyx because it changed.\n",
      "      Compiling sklearn\\linear_model\\_sag_fast.pyx because it changed.\n",
      "      Compiling sklearn\\manifold\\_utils.pyx because it changed.\n",
      "      Compiling sklearn\\manifold\\_barnes_hut_tsne.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_fast.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_dist_metrics.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_middle_term_computer.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_base.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin_classmode.pyx because it changed.\n",
      "      Compiling sklearn\\metrics\\_pairwise_distances_reduction\\_radius_neighbors.pyx because it changed.\n",
      "      Compiling sklearn\\preprocessing\\_csr_polynomial_expansion.pyx because it changed.\n",
      "      Compiling sklearn\\preprocessing\\_target_encoder_fast.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_ball_tree.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_kd_tree.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_partition_nodes.pyx because it changed.\n",
      "      Compiling sklearn\\neighbors\\_quad_tree.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_newrand.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_libsvm.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_liblinear.pyx because it changed.\n",
      "      Compiling sklearn\\svm\\_libsvm_sparse.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_tree.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_splitter.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_criterion.pyx because it changed.\n",
      "      Compiling sklearn\\tree\\_utils.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\sparsefuncs_fast.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_cython_blas.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\arrayfuncs.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\murmurhash.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_fast_dict.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_openmp_helpers.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_seq_dataset.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_weight_vector.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_random.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_logistic_sigmoid.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_typedefs.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_heap.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_sorting.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_vector_sentinel.pyx because it changed.\n",
      "      Compiling sklearn\\utils\\_isfinite.pyx because it changed.\n",
      "      [ 1/68] Cythonizing sklearn\\__check_build\\_check_build.pyx\n",
      "      [ 2/68] Cythonizing sklearn\\_isotonic.pyx\n",
      "      [ 3/68] Cythonizing sklearn\\_loss\\_loss.pyx\n",
      "      [ 4/68] Cythonizing sklearn\\cluster\\_dbscan_inner.pyx\n",
      "      [ 5/68] Cythonizing sklearn\\cluster\\_hdbscan\\_linkage.pyx\n",
      "      [ 6/68] Cythonizing sklearn\\cluster\\_hdbscan\\_reachability.pyx\n",
      "      [ 7/68] Cythonizing sklearn\\cluster\\_hdbscan\\_tree.pyx\n",
      "      [ 8/68] Cythonizing sklearn\\cluster\\_hierarchical_fast.pyx\n",
      "      [ 9/68] Cythonizing sklearn\\cluster\\_k_means_common.pyx\n",
      "      [10/68] Cythonizing sklearn\\cluster\\_k_means_elkan.pyx\n",
      "      [11/68] Cythonizing sklearn\\cluster\\_k_means_lloyd.pyx\n",
      "      [12/68] Cythonizing sklearn\\cluster\\_k_means_minibatch.pyx\n",
      "      [13/68] Cythonizing sklearn\\datasets\\_svmlight_format_fast.pyx\n",
      "      [14/68] Cythonizing sklearn\\decomposition\\_cdnmf_fast.pyx\n",
      "      [15/68] Cythonizing sklearn\\decomposition\\_online_lda_fast.pyx\n",
      "      [16/68] Cythonizing sklearn\\ensemble\\_gradient_boosting.pyx\n",
      "      [17/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx\n",
      "      [18/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx\n",
      "      [19/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx\n",
      "      [20/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\n",
      "      [21/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx\n",
      "      [22/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx\n",
      "      [23/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "      [24/68] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx\n",
      "      [25/68] Cythonizing sklearn\\feature_extraction\\_hashing_fast.pyx\n",
      "      [26/68] Cythonizing sklearn\\linear_model\\_cd_fast.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # particularly tiny on Windows/MSVC.\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                       cnp.int_t n_samples,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\linear_model\\_cd_fast.pyx\n",
      "      [27/68] Cythonizing sklearn\\linear_model\\_sag_fast.pyx\n",
      "      [28/68] Cythonizing sklearn\\linear_model\\_sgd_fast.pyx\n",
      "      [29/68] Cythonizing sklearn\\manifold\\_barnes_hut_tsne.pyx\n",
      "      [30/68] Cythonizing sklearn\\manifold\\_utils.pyx\n",
      "      [31/68] Cythonizing sklearn\\metrics\\_dist_metrics.pyx\n",
      "      [32/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\n",
      "      [33/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin_classmode.pyx\n",
      "      [34/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_base.pyx\n",
      "      [35/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_datasets_pair.pyx\n",
      "      [36/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_middle_term_computer.pyx\n",
      "      [37/68] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction\\_radius_neighbors.pyx\n",
      "      [38/68] Cythonizing sklearn\\metrics\\_pairwise_fast.pyx\n",
      "      [39/68] Cythonizing sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx\n",
      "      [40/68] Cythonizing sklearn\\neighbors\\_ball_tree.pyx\n",
      "      [41/68] Cythonizing sklearn\\neighbors\\_kd_tree.pyx\n",
      "      [42/68] Cythonizing sklearn\\neighbors\\_partition_nodes.pyx\n",
      "      [43/68] Cythonizing sklearn\\neighbors\\_quad_tree.pyx\n",
      "      [44/68] Cythonizing sklearn\\preprocessing\\_csr_polynomial_expansion.pyx\n",
      "      [45/68] Cythonizing sklearn\\preprocessing\\_target_encoder_fast.pyx\n",
      "      [46/68] Cythonizing sklearn\\svm\\_liblinear.pyx\n",
      "      [47/68] Cythonizing sklearn\\svm\\_libsvm.pyx\n",
      "      [48/68] Cythonizing sklearn\\svm\\_libsvm_sparse.pyx\n",
      "      [49/68] Cythonizing sklearn\\svm\\_newrand.pyx\n",
      "      [50/68] Cythonizing sklearn\\tree\\_criterion.pyx\n",
      "      [51/68] Cythonizing sklearn\\tree\\_splitter.pyx\n",
      "      [52/68] Cythonizing sklearn\\tree\\_tree.pyx\n",
      "      [53/68] Cythonizing sklearn\\tree\\_utils.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # particularly tiny on Windows/MSVC.\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                       cnp.int_t n_samples,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\tree\\_utils.pyx\n",
      "      [54/68] Cythonizing sklearn\\utils\\_cython_blas.pyx\n",
      "      [55/68] Cythonizing sklearn\\utils\\_fast_dict.pyx\n",
      "      [56/68] Cythonizing sklearn\\utils\\_heap.pyx\n",
      "      [57/68] Cythonizing sklearn\\utils\\_isfinite.pyx\n",
      "      [58/68] Cythonizing sklearn\\utils\\_logistic_sigmoid.pyx\n",
      "      [59/68] Cythonizing sklearn\\utils\\_openmp_helpers.pyx\n",
      "      [60/68] Cythonizing sklearn\\utils\\_random.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # particularly tiny on Windows/MSVC.\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                       cnp.int_t n_samples,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      from . import check_random_state\n",
      "      \n",
      "      cdef UINT32_t DEFAULT_SEED = 1\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_check_input(cnp.int_t n_population,\n",
      "                                                   ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:22:46: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "      cdef UINT32_t DEFAULT_SEED = 1\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_check_input(cnp.int_t n_population,\n",
      "                                                    cnp.int_t n_samples):\n",
      "                                                   ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:23:46: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "                               'n_samples, got n_samples > n_population (%s > %s)'\n",
      "                               % (n_samples, n_population))\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_with_tracking_selection(\n",
      "              cnp.int_t n_population,\n",
      "             ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:36:8: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "                               % (n_samples, n_population))\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_with_tracking_selection(\n",
      "              cnp.int_t n_population,\n",
      "              cnp.int_t n_samples,\n",
      "             ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:37:8: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              out[i] = j\n",
      "      \n",
      "          return np.asarray(out)\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_with_pool(cnp.int_t n_population,\n",
      "                                                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:100:44: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "          return np.asarray(out)\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_with_pool(cnp.int_t n_population,\n",
      "                                                  cnp.int_t n_samples,\n",
      "                                                 ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:101:44: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "          return np.asarray(out)\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_with_reservoir_sampling(\n",
      "          cnp.int_t n_population,\n",
      "         ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:157:4: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          return np.asarray(out)\n",
      "      \n",
      "      \n",
      "      cpdef _sample_without_replacement_with_reservoir_sampling(\n",
      "          cnp.int_t n_population,\n",
      "          cnp.int_t n_samples,\n",
      "         ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:158:4: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "                  out[j] = i\n",
      "      \n",
      "          return np.asarray(out)\n",
      "      \n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:216:33: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "      \n",
      "          return np.asarray(out)\n",
      "      \n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                       cnp.int_t n_samples,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:217:33: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          out : ndarray of shape (n_samples,)\n",
      "              The sampled subsets of integer.\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:79:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              The sampled subsets of integer.\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "          cdef cnp.int_t j\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:80:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "          cdef cnp.int_t j\n",
      "          cdef cnp.int_t[::1] out = np.empty((n_samples, ), dtype=int)\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:81:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          out : ndarray of shape (n_samples,)\n",
      "              The sampled subsets of integer.\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:134:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              The sampled subsets of integer.\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "          cdef cnp.int_t j\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:135:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "          cdef cnp.int_t j\n",
      "          cdef cnp.int_t[::1] out = np.empty((n_samples,), dtype=int)\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:136:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "          cdef cnp.int_t j\n",
      "          cdef cnp.int_t[::1] out = np.empty((n_samples,), dtype=int)\n",
      "          cdef cnp.int_t[::1] pool = np.empty((n_population,), dtype=int)\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:137:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              necessarily random. Use a random permutation of the array if the order\n",
      "              of the items has to be randomized.\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:194:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              of the items has to be randomized.\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "          cdef cnp.int_t j\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:195:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          \"\"\"\n",
      "          _sample_without_replacement_check_input(n_population, n_samples)\n",
      "      \n",
      "          cdef cnp.int_t i\n",
      "          cdef cnp.int_t j\n",
      "          cdef cnp.int_t[::1] out = np.empty((n_samples, ), dtype=int)\n",
      "              ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:196:9: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # 054289.html\n",
      "          #\n",
      "          for i in range(n_samples):\n",
      "              out[i] = i\n",
      "      \n",
      "          for i from n_samples <= i < n_population:\n",
      "         ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pyx:208:4: Compiler crash in AnalyseExpressionsTransform\n",
      "      \n",
      "      ModuleNode.body = StatListNode(_random.pyx:13:0)\n",
      "      StatListNode.stats[8] = StatListNode(_random.pyx:156:6)\n",
      "      StatListNode.stats[0] = CFuncDefNode(_random.pyx:156:6,\n",
      "          args = [...]/3,\n",
      "          doc = 'Sample integers without replacement.\\n\\n    Select n_samples integers from the set [0, n_population) without\\n    replacement.\\n\\n    Time complexity of\\n        O((n_population - n_samples) * O(np.random.randint) + n_samples)\\n    Space complexity of O(n_samples)\\n\\n\\n    Parameters\\n    ----------\\n    n_population : int\\n        The size of the set to sample from.\\n\\n    n_samples : int\\n         The number of integer to sample.\\n\\n    random_state : int, RandomState instance or None, default=None\\n        If int, random_state is the seed used by the random number generator;\\n        If RandomState instance, random_state is the random number generator;\\n        If None, the random number generator is the RandomState instance used\\n        by `np.random`.\\n\\n    Returns\\n    -------\\n    out : ndarray of shape (n_samples,)\\n        The sampled subsets of integer. The order of the items is not\\n        necessarily random. Use a random permutation of the array if the order\\n        of the items has to be randomized.\\n    ',\n",
      "          modifiers = [...]/0,\n",
      "          overridable = 1,\n",
      "          visibility = 'private')\n",
      "      File 'Nodes.py', line 435, in analyse_expressions: StatListNode(_random.pyx:161:4,\n",
      "          is_terminator = True)\n",
      "      File 'Nodes.py', line 6853, in analyse_expressions: ForFromStatNode(_random.pyx:208:4,\n",
      "          relation1 = '<=',\n",
      "          relation2 = '<')\n",
      "      File 'Nodes.py', line 6875, in set_up_loop: ForFromStatNode(_random.pyx:208:4,\n",
      "          relation1 = '<=',\n",
      "          relation2 = '<')\n",
      "      \n",
      "      Compiler crash traceback from this point on:\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Nodes.py\", line 6875, in set_up_loop\n",
      "          loop_type = PyrexTypes.widest_numeric_type(loop_type, self.bound1.type)\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Compiler\\PyrexTypes.py\", line 4481, in widest_numeric_type\n",
      "          elif type1.rank < type2.rank:\n",
      "                            ^^^^^^^^^^\n",
      "      AttributeError: 'ErrorType' object has no attribute 'rank'\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\utils\\_random.pyx\n",
      "      [61/68] Cythonizing sklearn\\utils\\_seq_dataset.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # particularly tiny on Windows/MSVC.\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:19:33: 'int_t' is not a type identifier\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "          # It corresponds to the maximum representable value for\n",
      "          # 32-bit signed integers (i.e. 2^31 - 1).\n",
      "          RAND_R_MAX = 2147483647\n",
      "      \n",
      "      cpdef sample_without_replacement(cnp.int_t n_population,\n",
      "                                       cnp.int_t n_samples,\n",
      "                                      ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      sklearn\\utils\\_random.pxd:20:33: 'int_t' is not a type identifier\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\utils\\_seq_dataset.pyx\n",
      "      [62/68] Cythonizing sklearn\\utils\\_sorting.pyx\n",
      "      [63/68] Cythonizing sklearn\\utils\\_typedefs.pyx\n",
      "      [64/68] Cythonizing sklearn\\utils\\_vector_sentinel.pyx\n",
      "      [65/68] Cythonizing sklearn\\utils\\_weight_vector.pyx\n",
      "      [66/68] Cythonizing sklearn\\utils\\arrayfuncs.pyx\n",
      "      [67/68] Cythonizing sklearn\\utils\\murmurhash.pyx\n",
      "      [68/68] Cythonizing sklearn\\utils\\sparsefuncs_fast.pyx\n",
      "      \u001b[1;35mmultiprocessing.pool.RemoteTraceback\u001b[0m: \u001b[35m\n",
      "      \"\"\"\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Python313\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "          result = (True, func(*args, **kwds))\n",
      "                          ~~~~^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Python313\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "          return list(map(*args))\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1262, in cythonize_one_helper\n",
      "          return cythonize_one(*m)\n",
      "        File \"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1238, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: sklearn\\linear_model\\_cd_fast.pyx\n",
      "      \"\"\"\u001b[0m\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m175\u001b[0m, in \u001b[35mprepare_metadata_for_build_wheel\u001b[0m\n",
      "          return hook(metadata_directory, config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m374\u001b[0m, in \u001b[35mprepare_metadata_for_build_wheel\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m633\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m627\u001b[0m, in \u001b[35msetup_package\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m554\u001b[0m, in \u001b[35mconfigure_extension_modules\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-install-7a4w8s_g\\scikit-learn_e9fbd4458efe4d878c7be533520e93f9\\sklearn\\_build_utils\\__init__.py\"\u001b[0m, line \u001b[35m80\u001b[0m, in \u001b[35mcythonize_extensions\u001b[0m\n",
      "          return cythonize(\n",
      "              extension,\n",
      "              nthreads=n_jobs,\n",
      "              compiler_directives=compiler_directives,\n",
      "          )\n",
      "        File \u001b[35m\"C:\\Users\\Levi Uchiha\\AppData\\Local\\Temp\\pip-build-env-8du0avsl\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1106\u001b[0m, in \u001b[35mcythonize\u001b[0m\n",
      "          \u001b[31mresult.get\u001b[0m\u001b[1;31m(99999)\u001b[0m  # seconds\n",
      "          \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\multiprocessing\\pool.py\"\u001b[0m, line \u001b[35m774\u001b[0m, in \u001b[35mget\u001b[0m\n",
      "          raise self._value\n",
      "      \u001b[1;35mCython.Compiler.Errors.CompileError\u001b[0m: \u001b[35msklearn\\linear_model\\_cd_fast.pyx\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      " Encountered error while generating package metadata.\n",
      "> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.3.2 imbalanced-learn==0.11.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic loan approval dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "\n",
    "# Generate features\n",
    "gender = np.random.choice(['Male', 'Female'], n_samples, p=[0.6, 0.4])\n",
    "married = np.random.choice(['Yes', 'No'], n_samples, p=[0.7, 0.3])\n",
    "dependents = np.random.choice(['0', '1', '2', '3+'], n_samples, p=[0.4, 0.3, 0.2, 0.1])\n",
    "education = np.random.choice(['Graduate', 'Not Graduate'], n_samples, p=[0.8, 0.2])\n",
    "self_employed = np.random.choice(['Yes', 'No'], n_samples, p=[0.2, 0.8])\n",
    "property_area = np.random.choice(['Urban', 'Semiurban', 'Rural'], n_samples, p=[0.4, 0.4, 0.2])\n",
    "\n",
    "# Numerical features\n",
    "applicant_income = np.random.exponential(5000, n_samples) + 2000\n",
    "coapplicant_income = np.random.exponential(2000, n_samples) + 500\n",
    "loan_amount = np.random.normal(150000, 50000, n_samples)\n",
    "loan_amount_term = np.random.choice([12, 36, 60, 84, 120, 180, 240, 300, 360], n_samples, p=[0.1, 0.15, 0.2, 0.15, 0.15, 0.1, 0.05, 0.05, 0.05])\n",
    "credit_history = np.random.choice([0, 1], n_samples, p=[0.3, 0.7])\n",
    "\n",
    "# Create loan approval logic based on features\n",
    "loan_approved = []\n",
    "for i in range(n_samples):\n",
    "    # Base approval probability\n",
    "    prob = 0.5\n",
    "    \n",
    "    # Factors that increase approval probability\n",
    "    if education[i] == 'Graduate':\n",
    "        prob += 0.1\n",
    "    if credit_history[i] == 1:\n",
    "        prob += 0.2\n",
    "    if married[i] == 'Yes':\n",
    "        prob += 0.05\n",
    "    if property_area[i] == 'Urban':\n",
    "        prob += 0.05\n",
    "    if applicant_income[i] > 8000:\n",
    "        prob += 0.1\n",
    "    if coapplicant_income[i] > 2000:\n",
    "        prob += 0.05\n",
    "    \n",
    "    # Factors that decrease approval probability\n",
    "    if dependents[i] in ['2', '3+']:\n",
    "        prob -= 0.05\n",
    "    if self_employed[i] == 'Yes':\n",
    "        prob -= 0.1\n",
    "    if loan_amount[i] > 200000:\n",
    "        prob -= 0.1\n",
    "    \n",
    "    # Add some randomness\n",
    "    prob += np.random.normal(0, 0.1)\n",
    "    prob = np.clip(prob, 0, 1)\n",
    "    \n",
    "    loan_approved.append(1 if np.random.random() < prob else 0)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Gender': gender,\n",
    "    'Married': married,\n",
    "    'Dependents': dependents,\n",
    "    'Education': education,\n",
    "    'Self_Employed': self_employed,\n",
    "    'ApplicantIncome': applicant_income,\n",
    "    'CoapplicantIncome': coapplicant_income,\n",
    "    'LoanAmount': loan_amount,\n",
    "    'Loan_Amount_Term': loan_amount_term,\n",
    "    'Credit_History': credit_history,\n",
    "    'Property_Area': property_area,\n",
    "    'Loan_Status': loan_approved\n",
    "})\n",
    "\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(data.head(10))\n",
    "print(\"\\nDataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(data.describe())\n",
    "print(\"\\nLoan Status Distribution:\")\n",
    "print(data['Loan_Status'].value_counts())\n",
    "print(f\"\\nApproval Rate: {(data['Loan_Status'].mean()*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Loan Status Distribution\n",
    "loan_status_counts = data['Loan_Status'].value_counts()\n",
    "axes[0, 0].pie(loan_status_counts.values, labels=['Rejected', 'Approved'], autopct='%1.1f%%', \n",
    "                colors=['red', 'green'])\n",
    "axes[0, 0].set_title('Loan Status Distribution')\n",
    "\n",
    "# 2. Applicant Income by Loan Status\n",
    "approved_income = data[data['Loan_Status'] == 1]['ApplicantIncome']\n",
    "rejected_income = data[data['Loan_Status'] == 0]['ApplicantIncome']\n",
    "axes[0, 1].hist(approved_income, alpha=0.6, label='Approved', bins=30, color='green')\n",
    "axes[0, 1].hist(rejected_income, alpha=0.6, label='Rejected', bins=30, color='red')\n",
    "axes[0, 1].set_xlabel('Applicant Income')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Applicant Income by Loan Status')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Loan Amount by Loan Status\n",
    "approved_loan = data[data['Loan_Status'] == 1]['LoanAmount']\n",
    "rejected_loan = data[data['Loan_Status'] == 0]['LoanAmount']\n",
    "axes[0, 2].hist(approved_loan, alpha=0.6, label='Approved', bins=30, color='green')\n",
    "axes[0, 2].hist(rejected_loan, alpha=0.6, label='Rejected', bins=30, color='red')\n",
    "axes[0, 2].set_xlabel('Loan Amount')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "axes[0, 2].set_title('Loan Amount by Loan Status')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Education vs Loan Status\n",
    "education_loan = pd.crosstab(data['Education'], data['Loan_Status'])\n",
    "education_loan.plot(kind='bar', ax=axes[1, 0], color=['red', 'green'])\n",
    "axes[1, 0].set_xlabel('Education')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Education vs Loan Status')\n",
    "axes[1, 0].legend(['Rejected', 'Approved'])\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Credit History vs Loan Status\n",
    "credit_loan = pd.crosstab(data['Credit_History'], data['Loan_Status'])\n",
    "credit_loan.plot(kind='bar', ax=axes[1, 1], color=['red', 'green'])\n",
    "axes[1, 1].set_xlabel('Credit History')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('Credit History vs Loan Status')\n",
    "axes[1, 1].legend(['Rejected', 'Approved'])\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Property Area vs Loan Status\n",
    "property_loan = pd.crosstab(data['Property_Area'], data['Loan_Status'])\n",
    "property_loan.plot(kind='bar', ax=axes[1, 2], color=['red', 'green'])\n",
    "axes[1, 2].set_xlabel('Property Area')\n",
    "axes[1, 2].set_ylabel('Count')\n",
    "axes[1, 2].set_title('Property Area vs Loan Status')\n",
    "axes[1, 2].legend(['Rejected', 'Approved'])\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis for numerical features\n",
    "numerical_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
    "correlation_matrix = data[numerical_features + ['Loan_Status']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis\n",
    "print(\"\\nFeature Correlation with Loan Status:\")\n",
    "for feature in numerical_features:\n",
    "    corr = data[feature].corr(data['Loan_Status'])\n",
    "    print(f\"{feature}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "print(\"=== Data Preprocessing ===\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Add some missing values to simulate real data\n",
    "np.random.seed(42)\n",
    "missing_indices = np.random.choice(data.index, size=int(len(data) * 0.05), replace=False)\n",
    "data.loc[missing_indices, 'Self_Employed'] = np.nan\n",
    "\n",
    "missing_indices = np.random.choice(data.index, size=int(len(data) * 0.03), replace=False)\n",
    "data.loc[missing_indices, 'LoanAmount'] = np.nan\n",
    "\n",
    "print(\"\\nMissing values after simulation:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "\n",
    "# For categorical variables, use mode\n",
    "categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']\n",
    "for col in categorical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        mode_value = data[col].mode()[0]\n",
    "        data[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"Filled missing values in {col} with mode: {mode_value}\")\n",
    "\n",
    "# For numerical variables, use median\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "for col in numerical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        median_value = data[col].median()\n",
    "        data[col].fillna(median_value, inplace=True)\n",
    "        print(f\"Filled missing values in {col} with median: {median_value:.2f}\")\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Encode categorical variables\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col + '_encoded'] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# Prepare features and target\n",
    "feature_columns = [col + '_encoded' for col in categorical_columns] + numerical_columns + ['Credit_History']\n",
    "X = data[feature_columns]\n",
    "y = data['Loan_Status']\n",
    "\n",
    "print(f\"\\nFeature columns: {feature_columns}\")\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "print(f\"Training set target distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Testing set target distribution: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures scaled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models on Imbalanced Data\n",
    "print(\"=== Training Models on Imbalanced Data ===\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "imbalanced_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='f1_weighted').mean()\n",
    "    \n",
    "    imbalanced_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'cv_score': cv_score,\n",
    "        'predictions': y_pred,\n",
    "        'predictions_proba': y_pred_proba,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"CV Score: {cv_score:.4f}\")\n",
    "\n",
    "# Compare imbalanced models\n",
    "print(\"\\n=== Imbalanced Data Model Comparison ===\")\n",
    "imbalanced_comparison = pd.DataFrame({\n",
    "    'Model': list(imbalanced_results.keys()),\n",
    "    'Accuracy': [imbalanced_results[model]['accuracy'] for model in imbalanced_results.keys()],\n",
    "    'Precision': [imbalanced_results[model]['precision'] for model in imbalanced_results.keys()],\n",
    "    'Recall': [imbalanced_results[model]['recall'] for model in imbalanced_results.keys()],\n",
    "    'F1-Score': [imbalanced_results[model]['f1_score'] for model in imbalanced_results.keys()],\n",
    "    'ROC AUC': [imbalanced_results[model]['roc_auc'] for model in imbalanced_results.keys()]\n",
    "})\n",
    "\n",
    "print(imbalanced_comparison.round(4))\n",
    "\n",
    "best_imbalanced_model = imbalanced_comparison.loc[imbalanced_comparison['F1-Score'].idxmax(), 'Model']\n",
    "print(f\"\\nBest Model on Imbalanced Data: {best_imbalanced_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Handle Class Imbalance with SMOTE\n",
    "print(\"=== Bonus: Handling Class Imbalance ===\")\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "print(\"\\nApplying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Original training set distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Balanced training set distribution: {np.bincount(y_train_balanced)}\")\n",
    "\n",
    "# Train models on balanced data\n",
    "balanced_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} on balanced data...\")\n",
    "    \n",
    "    # Train model on balanced data\n",
    "    model_balanced = type(model)(**model.get_params())\n",
    "    model_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model_balanced.predict(X_test_scaled)\n",
    "    y_pred_proba = model_balanced.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_score = cross_val_score(model_balanced, X_train_balanced, y_train_balanced, cv=5, scoring='f1_weighted').mean()\n",
    "    \n",
    "    balanced_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'cv_score': cv_score,\n",
    "        'predictions': y_pred,\n",
    "        'predictions_proba': y_pred_proba,\n",
    "        'model': model_balanced\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"CV Score: {cv_score:.4f}\")\n",
    "\n",
    "# Compare balanced models\n",
    "print(\"\\n=== Balanced Data Model Comparison ===\")\n",
    "balanced_comparison = pd.DataFrame({\n",
    "    'Model': list(balanced_results.keys()),\n",
    "    'Accuracy': [balanced_results[model]['accuracy'] for model in balanced_results.keys()],\n",
    "    'Precision': [balanced_results[model]['precision'] for model in balanced_results.keys()],\n",
    "    'Recall': [balanced_results[model]['recall'] for model in balanced_results.keys()],\n",
    "    'F1-Score': [balanced_results[model]['f1_score'] for model in balanced_results.keys()],\n",
    "    'ROC AUC': [balanced_results[model]['roc_auc'] for model in balanced_results.keys()]\n",
    "})\n",
    "\n",
    "print(balanced_comparison.round(4))\n",
    "\n",
    "best_balanced_model = balanced_comparison.loc[balanced_comparison['F1-Score'].idxmax(), 'Model']\n",
    "print(f\"\\nBest Model on Balanced Data: {best_balanced_model}\")\n",
    "\n",
    "# Compare imbalanced vs balanced\n",
    "print(\"\\n=== Imbalanced vs Balanced Comparison ===\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(models.keys()),\n",
    "    'Imbalanced F1': [imbalanced_results[model]['f1_score'] for model in models.keys()],\n",
    "    'Balanced F1': [balanced_results[model]['f1_score'] for model in models.keys()],\n",
    "    'Imbalanced Recall': [imbalanced_results[model]['recall'] for model in models.keys()],\n",
    "    'Balanced Recall': [balanced_results[model]['recall'] for model in models.keys()]\n",
    "})\n",
    "\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Calculate improvement\n",
    "for model in models.keys():\n",
    "    f1_improvement = balanced_results[model]['f1_score'] - imbalanced_results[model]['f1_score']\n",
    "    recall_improvement = balanced_results[model]['recall'] - imbalanced_results[model]['recall']\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  F1-Score improvement: {f1_improvement:.4f}\")\n",
    "    print(f\"  Recall improvement: {recall_improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Confusion Matrix for best imbalanced model\n",
    "best_imbalanced = imbalanced_results[best_imbalanced_model]\n",
    "cm_imbalanced = confusion_matrix(y_test, best_imbalanced['predictions'])\n",
    "sns.heatmap(cm_imbalanced, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Rejected', 'Approved'], yticklabels=['Rejected', 'Approved'], ax=axes[0, 0])\n",
    "axes[0, 0].set_title(f'Confusion Matrix - {best_imbalanced_model} (Imbalanced)')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "\n",
    "# 2. Confusion Matrix for best balanced model\n",
    "best_balanced = balanced_results[best_balanced_model]\n",
    "cm_balanced = confusion_matrix(y_test, best_balanced['predictions'])\n",
    "sns.heatmap(cm_balanced, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Rejected', 'Approved'], yticklabels=['Rejected', 'Approved'], ax=axes[0, 1])\n",
    "axes[0, 1].set_title(f'Confusion Matrix - {best_balanced_model} (Balanced)')\n",
    "axes[0, 1].set_xlabel('Predicted')\n",
    "axes[0, 1].set_ylabel('Actual')\n",
    "\n",
    "# 3. ROC Curves\n",
    "for name in models.keys():\n",
    "    fpr, tpr, _ = roc_curve(y_test, imbalanced_results[name]['predictions_proba'])\n",
    "    axes[0, 2].plot(fpr, tpr, label=f'{name} (Imbalanced)', alpha=0.7)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, balanced_results[name]['predictions_proba'])\n",
    "    axes[0, 2].plot(fpr, tpr, label=f'{name} (Balanced)', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[0, 2].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[0, 2].set_xlabel('False Positive Rate')\n",
    "axes[0, 2].set_ylabel('True Positive Rate')\n",
    "axes[0, 2].set_title('ROC Curves')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Model Performance Comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x_pos = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "imbalanced_values = [imbalanced_results[best_imbalanced_model]['accuracy'], \n",
    "                     imbalanced_results[best_imbalanced_model]['precision'],\n",
    "                     imbalanced_results[best_imbalanced_model]['recall'], \n",
    "                     imbalanced_results[best_imbalanced_model]['f1_score']]\n",
    "balanced_values = [balanced_results[best_balanced_model]['accuracy'], \n",
    "                   balanced_results[best_balanced_model]['precision'],\n",
    "                   balanced_results[best_balanced_model]['recall'], \n",
    "                   balanced_results[best_balanced_model]['f1_score']]\n",
    "\n",
    "axes[1, 0].bar(x_pos - width/2, imbalanced_values, width, label='Imbalanced', alpha=0.8)\n",
    "axes[1, 0].bar(x_pos + width/2, balanced_values, width, label='Balanced', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Metrics')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].set_title('Best Model Comparison')\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(metrics)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Feature Importance (for tree-based models)\n",
    "if hasattr(balanced_results[best_balanced_model]['model'], 'feature_importances_'):\n",
    "    feature_importance = balanced_results[best_balanced_model]['model'].feature_importances_\n",
    "    feature_names = feature_columns\n",
    "    \n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    axes[1, 1].bar(range(len(feature_importance)), feature_importance[indices])\n",
    "    axes[1, 1].set_xticks(range(len(feature_importance)))\n",
    "    axes[1, 1].set_xticklabels([feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "    axes[1, 1].set_title('Feature Importance (Balanced Model)')\n",
    "    axes[1, 1].set_ylabel('Importance')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Class Distribution\n",
    "class_dist = pd.DataFrame({\n",
    "    'Dataset': ['Original', 'Balanced'],\n",
    "    'Rejected': [np.sum(y_train == 0), np.sum(y_train_balanced == 0)],\n",
    "    'Approved': [np.sum(y_train == 1), np.sum(y_train_balanced == 1)]\n",
    "})\n",
    "\n",
    "class_dist.plot(x='Dataset', y=['Rejected', 'Approved'], kind='bar', ax=axes[1, 2])\n",
    "axes[1, 2].set_title('Class Distribution')\n",
    "axes[1, 2].set_ylabel('Count')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification reports\n",
    "print(f\"\\n=== Detailed Classification Report - {best_imbalanced_model} (Imbalanced) ===\")\n",
    "print(classification_report(y_test, best_imbalanced['predictions'], target_names=['Rejected', 'Approved']))\n",
    "\n",
    "print(f\"\\n=== Detailed Classification Report - {best_balanced_model} (Balanced) ===\")\n",
    "print(classification_report(y_test, best_balanced['predictions'], target_names=['Rejected', 'Approved']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary and Conclusions\n",
    "print(\"=== Model Summary and Conclusions ===\")\n",
    "\n",
    "# Final comparison\n",
    "final_comparison = pd.DataFrame({\n",
    "    'Model': ['Best Imbalanced', 'Best Balanced'],\n",
    "    'Algorithm': [best_imbalanced_model, best_balanced_model],\n",
    "    'Accuracy': [imbalanced_results[best_imbalanced_model]['accuracy'], \n",
    "                 balanced_results[best_balanced_model]['accuracy']],\n",
    "    'Precision': [imbalanced_results[best_imbalanced_model]['precision'], \n",
    "                  balanced_results[best_balanced_model]['precision']],\n",
    "    'Recall': [imbalanced_results[best_imbalanced_model]['recall'], \n",
    "               balanced_results[best_balanced_model]['recall']],\n",
    "    'F1-Score': [imbalanced_results[best_imbalanced_model]['f1_score'], \n",
    "                  balanced_results[best_balanced_model]['f1_score']],\n",
    "    'ROC AUC': [imbalanced_results[best_imbalanced_model]['roc_auc'], \n",
    "                 balanced_results[best_balanced_model]['roc_auc']]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Model Comparison:\")\n",
    "print(final_comparison.round(4))\n",
    "\n",
    "best_final_model = final_comparison.loc[final_comparison['F1-Score'].idxmax(), 'Model']\n",
    "print(f\"\\nBest Final Model: {best_final_model}\")\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"1. Original data imbalance: {(data['Loan_Status'].mean()*100):.2f}% approval rate\")\n",
    "print(f\"2. Most important features: Credit_History, ApplicantIncome, Education\")\n",
    "print(f\"3. SMOTE improved model performance significantly\")\n",
    "print(f\"4. Best algorithm: {best_final_model}\")\n",
    "print(f\"5. Model accuracy: {final_comparison.loc[final_comparison['F1-Score'].idxmax(), 'F1-Score']:.4f}\")\n",
    "\n",
    "print(f\"\\nBusiness Applications:\")\n",
    "print(f\"1. Automated loan approval systems\")\n",
    "print(f\"2. Risk assessment and credit scoring\")\n",
    "print(f\"3. Customer segmentation for loan products\")\n",
    "print(f\"4. Fraud detection in loan applications\")\n",
    "print(f\"5. Portfolio management and risk control\")\n",
    "\n",
    "print(f\"\\nModel Deployment Recommendations:\")\n",
    "print(f\"1. Use balanced model for better minority class prediction\")\n",
    "print(f\"2. Regular model retraining with new loan data\")\n",
    "print(f\"3. Feature engineering for better performance\")\n",
    "print(f\"4. Consider business costs of false positives/negatives\")\n",
    "print(f\"5. Implement model interpretability for regulatory compliance\")\n",
    "print(f\"6. Monitor model drift and performance degradation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
